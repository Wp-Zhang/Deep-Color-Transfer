

<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="light"
  data-auto-appearance="true"><head>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Final Report &middot; Deep Color Transfer</title>
  <meta name="title" content="Final Report &middot; Deep Color Transfer" />
  
  <meta name="description" content="A course project of CS7150 at Northeastern University, MA." />
  
  
  
  <link rel="canonical" href="https://wp-zhang.github.io/Deep-Color-Transfer/posts/report/" />
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/Deep-Color-Transfer/css/main.bundle.min.ace9375a3f0b260cb850f7090e378e9aff6e31d0ce1400c0ea8cec3a344862059bc4ee5345e70229d3da0da4f16d1fea7bc2965d94dff0f537a186bff8ddfe4f.css"
    integrity="sha512-rOk3Wj8LJgy4UPcJDjeOmv9uMdDOFADA6ozsOjRIYgWbxO5TRecCKdPaDaTxbR/qe8KWXZTf8PU3oYa/&#43;N3&#43;Tw==" />
  
  
  <script type="text/javascript" src="/Deep-Color-Transfer/js/main.min.cf83e1357eefb8bdf1542850d66d8007d620e4050b5715dc83f4a921d36ce9ce47d0d13c5d85f2b0ff8318d2877eec2f63b931bd47417a81a538327af927da3e.js" integrity="sha512-z4PhNX7vuL3xVChQ1m2AB9Yg5AULVxXcg/SpIdNs6c5H0NE8XYXysP&#43;DGNKHfuwvY7kxvUdBeoGlODJ6&#43;SfaPg=="></script>
  
  
  <script type="text/javascript" src="/Deep-Color-Transfer/js/appearance.min.f94f4c4636d9e3ec8f5ee53cdc8ffa3d01bf87cd92ac85e6797550b1e2b80dc9118d838f3eb24c55109352455e72ff082dfe560283154e5a8f87fd75107b59c4.js"
    integrity="sha512-&#43;U9MRjbZ4&#43;yPXuU83I/6PQG/h82SrIXmeXVQseK4DckRjYOPPrJMVRCTUkVecv8ILf5WAoMVTlqPh/11EHtZxA=="></script>
  
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/Deep-Color-Transfer/js/main.bundle.min.3505add38a70acba51f9557ef4857df3e22668f612f62e52b3d5c4206205c5466595b8aeab4e238ac2225b9ff74bff24fee5b8d68940264e5bac7d35f1d7d7b5.js"
    integrity="sha512-NQWt04pwrLpR&#43;VV&#43;9IV98&#43;ImaPYS9i5Ss9XEIGIFxUZllbiuq04jisIiW5/3S/8k/uW41olAJk5brH018dfXtQ==" data-copy="" data-copied=""></script>
  
  <script src="/js/zoom.min.js"></script>
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/Deep-Color-Transfer/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/Deep-Color-Transfer/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/Deep-Color-Transfer/favicon-16x16.png" />
  <link rel="manifest" href="/Deep-Color-Transfer/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:title" content="Final Report" />
<meta property="og:description" content="Final report draft." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wp-zhang.github.io/Deep-Color-Transfer/posts/report/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-12-05T00:00:00+00:00" /><meta property="og:site_name" content="Deep Color Transfer" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Final Report"/>
<meta name="twitter:description" content="Final report draft."/>

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Final Report",
    "headline": "Final Report",
    "description": "Final report draft.",
    "abstract": "Deep color transfer is an approach to extracting the histogram containing color information from the source and the reference image, then transferring the color between the image pair based on the histogram using a deep neural network.",
    "inLanguage": "en",
    "url" : "https:\/\/wp-zhang.github.io\/Deep-Color-Transfer\/posts\/report\/",
    "author" : {
      "@type": "Person",
      "name": "Deep Color Transfer"
    },
    "copyrightYear": "2022",
    "dateCreated": "2022-12-05T00:00:00\u002b00:00",
    "datePublished": "2022-12-05T00:00:00\u002b00:00",
    
    "dateModified": "2022-12-05T00:00:00\u002b00:00",
    
    
    
    "mainEntityOfPage": "true",
    "wordCount": "2346"
  }]
  </script>


  
  
  <meta name="author" content="Deep Color Transfer" />
  
  
  
  <link href="https://github.com/Wp-Zhang/Deep-Color-Transfer" rel="me" />
  
  
  
  





  
  
  <link
    type="text/css" rel="stylesheet"
    href="/Deep-Color-Transfer/lib/katex/katex.min.990c289bc36ce28a7e1f6f680e40ff2d73bf3ac5cfbc215f92066414056b86178fcd12d4f0d508dcd926e373615944a68f7a7909c6b61d3124310997411c0341.css"
    integrity="sha512-mQwom8Ns4op&#43;H29oDkD/LXO/OsXPvCFfkgZkFAVrhhePzRLU8NUI3Nkm43NhWUSmj3p5Cca2HTEkMQmXQRwDQQ=="
  />
  
  
  <script defer src="/Deep-Color-Transfer/lib/katex/katex.min.b0748d2c40912522be045b3b13c0e215cea97fa9fdd1b2c8f391268b0d6386b79db9984add55e0abd978900b7d79320760072e4012872f4d502ace3fdd7825f2.js" integrity="sha512-sHSNLECRJSK&#43;BFs7E8DiFc6pf6n90bLI85Emiw1jhreduZhK3VXgq9l4kAt9eTIHYAcuQBKHL01QKs4/3Xgl8g=="></script>
  
  
  <script defer src="/Deep-Color-Transfer/lib/katex/auto-render.min.8968ae052e67b7aafad1f0b3dba35dd19a9ed276e4d594c841b9772afee462c5fec8a314147ce3687dbe02733abe9d97b3e80d99a0405562634a6b8fc3be847e.js" integrity="sha512-iWiuBS5nt6r60fCz26Nd0Zqe0nbk1ZTIQbl3Kv7kYsX&#43;yKMUFHzjaH2&#43;AnM6vp2Xs&#43;gNmaBAVWJjSmuPw76Efg==" onload="renderMathInElement(document.body);"></script>
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  


  
  
  
  


  
  
  
  
  
</head><body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div style="padding-left:0;padding-right:0"
    class="flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            <a href="/Deep-Color-Transfer/" class="text-base font-medium text-gray-500 hover:text-gray-900">Deep Color Transfer</a>
            
            
        </nav>
        <div class="hidden md:flex items-center space-x-5 md:ml-12">

            
            
            <a href=""  class="text-base font-medium text-gray-500 hover:text-gray-900" title="">
                


                
                Example
            </a>
            
            <a href="https://github.com/Wp-Zhang/Deep-Color-Transfer"  target="_blank" class="text-base font-medium text-gray-500 hover:text-gray-900" title="">
                


                
                Code
            </a>
            
            <a href="/Deep-Color-Transfer/posts/"  class="text-base font-medium text-gray-500 hover:text-gray-900" title="Posts">
                


                
                Posts
            </a>
            
            

            


            
            <button id="search-button" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            
            <div
                class="ltr:mr-14 rtl:ml-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400">
                <button id="appearance-switcher" type="button">
                    <div class="flex items-center justify-center h-12 dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden h-12 dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </div>
        <div class="flex md:hidden items-center space-x-5 md:ml-12">

            <span></span>

            


            
            <button id="search-button-mobile" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" type="button" style="margin-right:5px">
                <div class="flex items-center justify-center h-12 dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden h-12 dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" for="menu-controller" class="block">
            <input type="checkbox" id="menu-controller" class="hidden" />
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:25px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-auto overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex movedown flex-col w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl sm:px-14 md:px-24 lg:px-32 sm:py-10 sm:pt-10">
                    <li class="mb-1">
                        <span class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    
                    
                    <li class="mb-1">
                        <a  class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                            href="" title="">
                            <span class="inline-block align-text-bottom">

</span>
                            
                            Example
                        </a>
                    </li>
                    
                    <li class="mb-1">
                        <a  target="_blank" class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                            href="https://github.com/Wp-Zhang/Deep-Color-Transfer" title="">
                            <span class="inline-block align-text-bottom">

</span>
                            
                            Code
                        </a>
                    </li>
                    
                    <li class="mb-1">
                        <a  class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
                            href="/Deep-Color-Transfer/posts/" title="Posts">
                            <span class="inline-block align-text-bottom">

</span>
                            
                            Posts
                        </a>
                    </li>
                    
                    

                </ul>
            </div>
        </label>
    </div>
</div>
  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  
  
  
  
  <header id="single_header" class="mt-5 max-w-prose">
    
    <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/Deep-Color-Transfer/"
      >Deep Color Transfer</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline ">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/Deep-Color-Transfer/posts/"
      >Posts</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/Deep-Color-Transfer/posts/report/"
      >Final Report</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      Final Report
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      




































<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2022-12-05 00:00:00 &#43;0000 UTC">5 December 2022</time><span class="px-2 text-primary-500">&middot;</span><span>2346 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">12 mins</span>
  

  
  
</div>







    </div>
  </header>
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
     
    <div class="order-first sm:max-w-prose lg:ml-auto px-0 lg:order-last lg:max-w-xs ltr:lg:pl-8 rtl:lg:pr-8">
      <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky  lg:top-10 ">
        <details open class="mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"
  >
    <nav id="TableOfContents">
  <ul>
    <li><a href="#1-introduction">1. Introduction</a></li>
    <li><a href="#2-related-work">2. Related work</a></li>
    <li><a href="#3-methodology">3. Methodology</a>
      <ul>
        <li><a href="#31-framework">3.1 Framework</a></li>
        <li><a href="#32-loss-function">3.2 Loss function</a></li>
      </ul>
    </li>
    <li><a href="#4-experiments">4. Experiments</a>
      <ul>
        <li><a href="#41-training">4.1 Training</a>
          <ul>
            <li><a href="#411-dataset-construction">4.1.1 Dataset construction</a></li>
            <li><a href="#412-implementation-details">4.1.2 Implementation details</a></li>
          </ul>
        </li>
        <li><a href="#42-evaluation">4.2 Evaluation</a></li>
      </ul>
    </li>
    <li><a href="#5-results">5. Results</a>
      <ul>
        <li><a href="#51-test-case-analysis">5.1 Test case analysis</a></li>
        <li><a href="#52-loss-analysis">5.2 Loss analysis</a></li>
      </ul>
    </li>
    <li><a href="#6-summary">6. Summary</a></li>
    <li><a href="#7-statement-of-contributions">7. Statement of contributions</a>
      <ul>
        <li>
          <ul>
            <li></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>
<details class="mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"
  >
    <nav id="TableOfContents">
  <ul>
    <li><a href="#1-introduction">1. Introduction</a></li>
    <li><a href="#2-related-work">2. Related work</a></li>
    <li><a href="#3-methodology">3. Methodology</a>
      <ul>
        <li><a href="#31-framework">3.1 Framework</a></li>
        <li><a href="#32-loss-function">3.2 Loss function</a></li>
      </ul>
    </li>
    <li><a href="#4-experiments">4. Experiments</a>
      <ul>
        <li><a href="#41-training">4.1 Training</a>
          <ul>
            <li><a href="#411-dataset-construction">4.1.1 Dataset construction</a></li>
            <li><a href="#412-implementation-details">4.1.2 Implementation details</a></li>
          </ul>
        </li>
        <li><a href="#42-evaluation">4.2 Evaluation</a></li>
      </ul>
    </li>
    <li><a href="#5-results">5. Results</a>
      <ul>
        <li><a href="#51-test-case-analysis">5.1 Test case analysis</a></li>
        <li><a href="#52-loss-analysis">5.2 Loss analysis</a></li>
      </ul>
    </li>
    <li><a href="#6-summary">6. Summary</a></li>
    <li><a href="#7-statement-of-contributions">7. Statement of contributions</a>
      <ul>
        <li>
          <ul>
            <li></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>

      </div>
      </div>
      
      <div class="min-w-0 min-h-0 max-w-prose">
        
        

<p>Deep color transfer is an approach to extracting the histogram containing color information from the source and the reference image, then transferring the color between the image pair based on the histogram using a deep neural network. Besides the source image and reference image, semantic segmentation results of both images are optional inputs that can help produce a more precise color transfer.
The method we adopted was published in 2020. Even though it can produce excellent color transfer effects, the size of the model is too large and models that can produce more precise semantic segmentation results have been proposed. We used BEiT v2 to generate more precise semantic segmentation results and a Color Transfer Network with fewer parameters to improve model efficiency. We leveraged knowledge distillation in training the new Color Transfer Network. Experimental results showed that our method could generate satisfying color transfer effects faster and support larger input images.</p>
<div id="1-introduction" class="anchor">1. Introduction></div>
<h2 class="relative group">1. Introduction 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1-introduction" aria-label="Anchor">#</a></span>        
    
</h2><p>Color is the most direct visual perception of an image and the central consideration when people edit their photographs. Color filters are commonly seen in the applications such as Instagram and TikTok. Color transfer in our project refers to adequately transferring the reference image&rsquo;s color to the source image while keeping the objects in the source images unchanged.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/demo_hu73dbfe7491fe95cacb6e1ee37b76076c_6176213_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/demo_hu73dbfe7491fe95cacb6e1ee37b76076c_6176213_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/demo_hu73dbfe7491fe95cacb6e1ee37b76076c_6176213_660x0_resize_box_3.png" alt="demo" />
  <figcaption>Figure 1: Example of Color transfer result</figcaption>
</figure>

</p>
<p>Our main contributions are summarized as follows:</p>
<ul>
<li>Introduced BEiT v2<a href="/Deep-Color-Transfer/posts/report/#ref1"  >
    [1]</a> to the histogram encode network and a Color Transfer Network with fewer parameters.</li>
<li>Applied knowledge distillation<a href="/Deep-Color-Transfer/posts/report/#ref2"  >
    [2]</a> during the training of the smaller model, significantly reducing the time of training and enabling the model to produce similar color transfer effects to the original model while increasing the inference speed and maximum resolution of input images.</li>
</ul>
<div id="2-related-work" class="anchor">2. Related work></div>
<h2 class="relative group">2. Related work 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2-related-work" aria-label="Anchor">#</a></span>        
    
</h2><p><em><strong>Color transfer</strong></em>
The Color transfer method is constantly evolving. The conventional approaches try to match the means and standard deviations of the source to reference images or calculate probability density functions. Other solutions are also based on the local color part, including the EM algorithm and neural representations. Lee et al. <a href="/Deep-Color-Transfer/posts/report/#ref3"  >
    [3]</a> adopted the idea from photorealistic image style transfer<a href="/Deep-Color-Transfer/posts/report/#ref4"  >
    [4]</a> and introduced neural network to color transfer.</p>
<p><em><strong>Semantic segmentation</strong></em>
BEiT v2<a href="/Deep-Color-Transfer/posts/report/#ref1"  >
    [1]</a> is the latest SOTA mask modeling method published in 2022. It proposed the VQ-KD(vector-quantized knowledge distillation) method, which discretizes a continuous semantic space that supervises masked image modeling rather than relying on image pixels. This approach highly promoted the accuracy of semantic segmentation compared. The previous method that the author used addressed semantic segmentation by incorporating high-order relations
and mixture of label contexts into MRF. They solved MRF by proposing a Convolutional Neural Network, which enables deterministic end-to-end computation in a single forward pass.</p>
<p><em><strong>Knowledge distillation</strong></em>
Knowledge distillation<a href="/Deep-Color-Transfer/posts/report/#ref2"  >
    [2]</a> refers to transferring knowledge from a large, heavy model to a smaller model that can be practically deployed under real-world constraints. In other words, a small &ldquo;student&rdquo; model learns to mimic a &ldquo;teacher&rdquo; model and leverage the teacher&rsquo;s knowledge to obtain similar or even higher accuracy.</p>
<div id="3-methodology" class="anchor">3. Methodology></div>
<h2 class="relative group">3. Methodology 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3-methodology" aria-label="Anchor">#</a></span>        
    
</h2><div id="31-framework" class="anchor">3.1 Framework></div>
<h3 class="relative group">3.1 Framework 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#31-framework" aria-label="Anchor">#</a></span>        
    
</h3><p>Our framework kept the basic ideas of the Histogram Encoding Network(HEN) and Color Transfer Network(CTN) from <a href="/Deep-Color-Transfer/posts/report/#ref3"  >
    [3]</a>. HEN is a convolutional neural network that includes eight convolution layers and eight subsequent leaky ReLU activation of each layer. CTN is composed of a U-Net to encode and decode input images and a refinement module to process the decoding result and generate the output image.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/model_structure_hu07e08fca357c5ef75ca68f416466a232_370537_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/model_structure_hu07e08fca357c5ef75ca68f416466a232_370537_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/model_structure_hu07e08fca357c5ef75ca68f416466a232_370537_660x0_resize_box_3.png" alt="model" />
  <figcaption>Figure 2: Framework of Color Transfer Network and Histogram Encoding network [3]</figcaption>
</figure>

</p>
<p>Input image \(I_s\) and reference image \(I_t\) will be converted to LAB color space first. Histograms \(H^l\) for L space and \(H^{ab}\) for ab space of each image will then be calculated. \(H^l\) and \(H^{ab}\) will be tiled and then concatenated together as \(H\). The HEN will encode \(H_s\) and \(H_t\) as feature vectors \(e_s\) and \(e_t\). To fuse spatial feature maps of \(I_s\) and 1D global feature vectors \(e_s\) and \(e_t\), we tile the feature vectors to form histogram feature maps \(e_s\) and \(e_t\) with the spatial size of the corresponding decoding layer in the CTN to be concatenated.</p>
<p>Semantic segmentation results are optional inputs of this framework. We ﬁrst compute local histograms from image regions with the same semantic labels and then feed the semantic-wise histograms into HEN to construct a spatially and semantically varying histogram feature map \(R_t\) instead of the global map \(e_t\). By doing this, CTN can receive more precise local information of the reference histogram, increasing the certainty in determining colors when the source and the reference image have different spatial compositions.</p>
<div id="32-loss-function" class="anchor">3.2 Loss function></div>
<h3 class="relative group">3.2 Loss function 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#32-loss-function" aria-label="Anchor">#</a></span>        
    
</h3><p>As the authors did in <a href="/Deep-Color-Transfer/posts/report/#ref3"  >
    [3]</a>, three types of losses are used to evaluate model performance and help with model training. Image loss \( L_{image} \) is the mean-squared error between the color transfer result \(\hat{I_t}\) and the ground-truth image \(I_t\).
To enforce the color transfer result \(\hat{I_t}\) to have a similar histogram with the reference image, histogram loss \(L_{hist} = MSE(\hat{H_t}, H_t)\) is introduced.
The role of each decoder layer in CTN is to up-sample information from the previous layer, we use multi-scale loss \(L_{multi}\) to enforce this role. It&rsquo;s defined by \(L_{multi} = \frac{1}{D}\sum_{d=1}^D MSE(\hat{I}^d_t,I_t^d)\), where \(D\) is the number of layers of the decoder.</p>
<p>These losses are combined with weights \( \lambda_1 \) and \( \lambda_2 \):</p>
<p>$$
L_{hard} = L_{image} + \lambda_1 * L_{hist} +\lambda_2 * L_{multi}
$$</p>
<p>For knowledge distillation, we redesigned the loss to include the distance between the teacher, the pre-trained model using the methods in <a href="/Deep-Color-Transfer/posts/report/#ref3"  >
    [3]</a>, and the student, our redesigned model with fewer parameters. The distillation loss is quite similar to the original loss, but we switched the ground-truth image \(I_t\) to the output of the teacher model.</p>
<img src="https://latex.codecogs.com/svg.image?L_{soft}&space;=&space;\text{MSE}(&space;\hat{I}^{student}_t,\hat{I}^{teacher}_t)&space;&plus;&space;\lambda_1&space;*&space;\text{MSE}(\hat{H_t}^{student},&space;\hat{H_t}^{teacher})&space;&plus;&space;\lambda_2&space;*&space;\frac{1}{D}&space;\sum&space;_{d=1}&space;^D&space;\text{MSE}&space;(&space;\hat{I}&space;^d&space;_{t\&space;\text{student}},&space;\hat{I}&space;^d&space;_{t\&space;\text{teacher}}&space;)" title="https://latex.codecogs.com/svg.image?L_{soft} = \text{MSE}( \hat{I}^{student}_t,\hat{I}^{teacher}_t) + \lambda_1 * \text{MSE}(\hat{H_t}^{student}, \hat{H_t}^{teacher}) + \lambda_2 * \frac{1}{D} \sum _{d=1} ^D \text{MSE} ( \hat{I} ^d _{t\ \text{student}}, \hat{I} ^d _{t\ \text{teacher}} )" />
<p>The loss of the student model is a combination of the hard loss and the soft loss:</p>
<p>$$
L = \alpha * L_{soft} + (1-\alpha) * L_{hard}
$$</p>
<div id="4-experiments" class="anchor">4. Experiments></div>
<h2 class="relative group">4. Experiments 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#4-experiments" aria-label="Anchor">#</a></span>        
    
</h2><div id="41-training" class="anchor">4.1 Training></div>
<h3 class="relative group">4.1 Training 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#41-training" aria-label="Anchor">#</a></span>        
    
</h3><div id="411-dataset-construction" class="anchor">4.1.1 Dataset construction></div>
<h4 class="relative group">4.1.1 Dataset construction 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#411-dataset-construction" aria-label="Anchor">#</a></span>        
    
</h4><p>The dataset we used is called MIT-Adobe 5K<a href="/Deep-Color-Transfer/posts/report/#ref5"  >
    [5]</a>, which comprises the raw set of 5000 images and five same-size retouched subsets from five different experts. This dataset is excellent for our task as the source-reference images here are almost the same except for color. This would accommodate the network to learn the histogram features easily and transfer color naturally. To initiate more possible combinations of image pairs, we performed color augmentation which transfers the average hue and saturation of the source image as the authors did in <a href="/Deep-Color-Transfer/posts/report/#ref3"  >
    [3]</a>. Besides color augmentation, we also adopted normal image augmentation methods like random crop and horizontal flip.</p>
<div id="412-implementation-details" class="anchor">4.1.2 Implementation details></div>
<h4 class="relative group">4.1.2 Implementation details 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#412-implementation-details" aria-label="Anchor">#</a></span>        
    
</h4><p>The whole network is built with the PyTorch framework, and we used 8 NVIDIA A40 GPUs to train our models. As the author only published low-performance code for model construction and testing, we built a scalable framework that supports multiple-GPU parallel training and backbone switching from scratch. Bin size when calculating histograms are \( B_{ab}=64 \), \(B_{l}=8\). We used Adam<a href="/Deep-Color-Transfer/posts/report/#ref6"  >
    [6]</a> as the optimizer with a learning rate of \(5*10^{-5}\), \(\beta_1 = 0.5\), \(\beta_2 = 0.999\). The weights of different losses are \(\lambda_1 = 10\), \(\lambda_2 = 10\), \(\alpha = 0.5\).</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/1_huf2b615f515b7ffed07d1943204455bd0_1414016_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/1_huf2b615f515b7ffed07d1943204455bd0_1414016_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/1_huf2b615f515b7ffed07d1943204455bd0_1414016_660x0_resize_box_3.png" alt="dataset" />
  <figcaption>Figure 3: Dataset construction</figcaption>
</figure>

</p>
<div id="42-evaluation" class="anchor">4.2 Evaluation></div>
<h3 class="relative group">4.2 Evaluation 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#42-evaluation" aria-label="Anchor">#</a></span>        
    
</h3><p>The loss curves of the training process using knowledge distillation are shown in figure 4 and 5. Blue lines are the loss of the student model while pink dashed lines indicate the loss of the teacher model, which can be seen as the ultimate goal of the student model. As shown in the loss curves, it only took 25 epochs for the student model to converge, which is much faster compared with the 115 epochs the teacher model took. The student model can produce similar color transfer effects to the teacher model with slightly higher image losses and unexpected lower histogram loss.</p>
<p>






<figure>
  <img class="my-0 rounded-md" src="imgs/train%20loss.png" alt="train loss" />
  <figcaption>Figure 4: Train loss</figcaption>
</figure>

</p>
<p>






<figure>
  <img class="my-0 rounded-md" src="imgs/val%20loss.png" alt="valid loss" />
  <figcaption>Figure 5: Validation loss</figcaption>
</figure>

</p>
<div id="5-results" class="anchor">5. Results></div>
<h2 class="relative group">5. Results 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#5-results" aria-label="Anchor">#</a></span>        
    
</h2><div id="51-test-case-analysis" class="anchor">5.1 Test case analysis></div>
<h3 class="relative group">5.1 Test case analysis 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#51-test-case-analysis" aria-label="Anchor">#</a></span>        
    
</h3><p>We selected images of different categories for the test dataset, including portrait, animal, mountain, building, desert, and abstract paintings. We can get image pairs with different levels of content relevance from permutations of these images. Figures 8, 9, and 10 are examples of the color transfer results of different image pairs.</p>
<p>For strong relevance image pairs with almost identical structure and contents, figure 6 shows that the color of the sky, trees, plants, sofa, and decorations in source and reference images are matched and transferred perfectly.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/strong_hu2497389239aa9c231bd314adefc2275e_5121584_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/strong_hu2497389239aa9c231bd314adefc2275e_5121584_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/strong_hu2497389239aa9c231bd314adefc2275e_5121584_660x0_resize_box_3.png" alt="strong" />
  <figcaption>Figure 6: Results of strong relevance image pairs</figcaption>
</figure>

</p>
<p>Weak relevance image pairs are those from the same categories with similar contents. For example, the images displayed in figure 7 all contain &ldquo;desert&rdquo; or &ldquo;building&rdquo;. However, the positions of semantic objects have less similarity than the strong ones. The output images indicate that the colors are transferred to the source images appreciably and naturally.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/weak_hu6032100626eb0ed90220fb5bc1be9e9d_5039323_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/weak_hu6032100626eb0ed90220fb5bc1be9e9d_5039323_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/weak_hu6032100626eb0ed90220fb5bc1be9e9d_5039323_660x0_resize_box_3.png" alt="weak" />
  <figcaption>Figure 7: Results of weak relevance images pairs</figcaption>
</figure>

</p>
<p>Figure 8 shows the color transfer results between irrelevance image pairs, where the input images&rsquo; content does not correlate. The two images of the first example in figure 8 are abstract digital paintings and have complex graphical shapes. The output demonstrates that our network could learn the histogram feature and transfer the primary color excellently.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/irrel_hua24d9f64afe7c4d29a67cf9f8a4f03a8_4838259_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/irrel_hua24d9f64afe7c4d29a67cf9f8a4f03a8_4838259_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/irrel_hua24d9f64afe7c4d29a67cf9f8a4f03a8_4838259_660x0_resize_box_3.png" alt="irrelevant" />
  <figcaption>Figure 8: Irrelevance image pairs’ result</figcaption>
</figure>

</p>
<p>Besides image pairs with different content correlations, we also compared the network&rsquo;s output with and without using semantic labels. The image in the bottom right corner of figure 9 is the model output without using the semantic label. It does not truly reflect all the colors contrasting with the one using the label on the left, indicating that semantic labels of the input images can help our model produce more precise color transfer results between semantically similar objects.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/seg_hu8fb84c5e55ed2eccd659dd298dff54ea_1092362_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/seg_hu8fb84c5e55ed2eccd659dd298dff54ea_1092362_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/seg_hu8fb84c5e55ed2eccd659dd298dff54ea_1092362_660x0_resize_box_3.png" alt="segs" />
  <figcaption>Figure 9: Comparison of the results with and without using semantic label</figcaption>
</figure>

</p>
<div id="52-loss-analysis" class="anchor">5.2 Loss analysis></div>
<h3 class="relative group">5.2 Loss analysis 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#52-loss-analysis" aria-label="Anchor">#</a></span>        
    
</h3><p>We calculated the hard loss of each image pair in the training dataset, and color transfer results of the top three images with the largest and smallest loss are shown in figure 10. Each column in figure 10 represents one data point. The source, reference, and output images are in the first, second, and third rows respectively.</p>
<p>








<figure>
  <img class="my-0 rounded-md" srcset='
          /Deep-Color-Transfer/posts/report/imgs/res1_hu2f4420883eebe130a9ae08dc95db671d_1860354_330x0_resize_box_3.png 330w,
          /Deep-Color-Transfer/posts/report/imgs/res1_hu2f4420883eebe130a9ae08dc95db671d_1860354_660x0_resize_box_3.png 660w' src="/Deep-Color-Transfer/posts/report/imgs/res1_hu2f4420883eebe130a9ae08dc95db671d_1860354_660x0_resize_box_3.png" alt="res1" />
  <figcaption>Figure 10: Top 3 image pairs with the largest and smallest loss</figcaption>
</figure>

</p>
<p>Our findings are listed below:</p>
<ul>
<li>
<p>Images with larger losses have more complex compositions than small ones, which means the features and colors are more challenging to be learned and transferred. Also, the semantic segmentation labels here are not precise enough to distinguish the tiny areas.</p>
</li>
<li>
<p>Our network is sensitive to the angle of an image. The source image is horizontally flipped in the second column, and the people&rsquo;s clothing and tree colors are misconverted.</p>
</li>
<li>
<p>The fewer different colors in the image pair, the better outcome could be produced. The three columns on the right show that image pairs with the smallest loss only contain one to two different colors.</p>
</li>
</ul>
<div id="6-summary" class="anchor">6. Summary></div>
<h2 class="relative group">6. Summary 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#6-summary" aria-label="Anchor">#</a></span>        
    
</h2><p>In this project, we built a deep-learning-based model for color transfer between images. We adopted the idea from <a href="/Deep-Color-Transfer/posts/report/#ref3"  >
    [3]</a> and utilized knowledge distillation to get a smaller model with similar performance to the original one, significantly reducing the training time and increasing the maximum supported input resolution. For image pairs with similar semantic objects but different compositions, we switched to BEiT v2 for generating semantic labels and greatly improved the color transfer accuracy.</p>
<p>Our model can produce excellent color transfer results for image pairs with different levels of content relevance. However, although we applied the SOTA segmentation model, the semantic labels are still not accurate enough when the contents are complex, leading to unsatisfying results. The general model without using semantic labels got more natural results in these cases.</p>
<p>In the future, encoder and decoder in the Color Transfer Network with different structures, e.g. transformers, can be tried. The structure of the Color Transfer Network can also be redesigned to support high-resolution input and output better.</p>
<div id="7-statement-of-contributions" class="anchor">7. Statement of contributions></div>
<h2 class="relative group">7. Statement of contributions 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#7-statement-of-contributions" aria-label="Anchor">#</a></span>        
    
</h2><p><strong>Weipeng Zhang:</strong> code, dataset preparation, model training, presentation, report.</p>
<p><strong>Yubing Gou:</strong> model testing and analysis, report.</p>
<hr>
<div id="ref1" class="anchor">[1] Zhiliang Peng, Li Dong, Hangbo Bao, Qixiang Ye, and Furu Wei. <em><strong>Beit v2: Masked image modeling with vector-quantized visual tokenizers.</strong></em> arXiv preprint arXiv:2208.06366, 2022. ></div>
<h5 class="relative group">[1] Zhiliang Peng, Li Dong, Hangbo Bao, Qixiang Ye, and Furu Wei. <em><strong>Beit v2: Masked image modeling with vector-quantized visual tokenizers.</strong></em> arXiv preprint arXiv:2208.06366, 2022.  
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#ref1" aria-label="Anchor">#</a></span>        
    
</h5><div id="ref2" class="anchor">[2] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. <em><strong>Distilling the knowledge in a neural network.</strong></em> arXiv preprint arXiv:1503.02531, 2(7), 2015.></div>
<h5 class="relative group">[2] Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. <em><strong>Distilling the knowledge in a neural network.</strong></em> arXiv preprint arXiv:1503.02531, 2(7), 2015. 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#ref2" aria-label="Anchor">#</a></span>        
    
</h5><div id="ref3" class="anchor">[3] Junyong Lee, Hyeongseok Son, Gunhee Lee, Jonghyeop Lee, Sunghyun Cho, and Seungyong Lee. <em><strong>Deep color transfer using histogram analogy.</strong></em> The Visual Computer, 36(10):2129–2143, 2020. ></div>
<h5 class="relative group">[3] Junyong Lee, Hyeongseok Son, Gunhee Lee, Jonghyeop Lee, Sunghyun Cho, and Seungyong Lee. <em><strong>Deep color transfer using histogram analogy.</strong></em> The Visual Computer, 36(10):2129–2143, 2020.  
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#ref3" aria-label="Anchor">#</a></span>        
    
</h5><div id="ref4" class="anchor">[4] Fujun Luan, Sylvain Paris, Eli Shechtman, and Kavita Bala. <em><strong>Deep photo style transfer.</strong></em> In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4990–4998, 2017.></div>
<h5 class="relative group">[4] Fujun Luan, Sylvain Paris, Eli Shechtman, and Kavita Bala. <em><strong>Deep photo style transfer.</strong></em> In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4990–4998, 2017. 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#ref4" aria-label="Anchor">#</a></span>        
    
</h5><div id="ref5" class="anchor">[5] Vladimir Bychkovsky, Sylvain Paris, Eric Chan, and Fr ́edo Durand. <em><strong>Learning photographic global tonal adjustment with a database of input / output image pairs.</strong></em> In The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition, 2011.></div>
<h5 class="relative group">[5] Vladimir Bychkovsky, Sylvain Paris, Eric Chan, and Fr ́edo Durand. <em><strong>Learning photographic global tonal adjustment with a database of input / output image pairs.</strong></em> In The Twenty-Fourth IEEE Conference on Computer Vision and Pattern Recognition, 2011. 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#ref5" aria-label="Anchor">#</a></span>        
    
</h5><div id="ref6" class="anchor">[6] Diederik P Kingma and Jimmy Ba. <em><strong>Adam: A method for stochastic optimization.</strong></em> arXiv preprint arXiv:1412.6980, 2014.></div>
<h5 class="relative group">[6] Diederik P Kingma and Jimmy Ba. <em><strong>Adam: A method for stochastic optimization.</strong></em> arXiv preprint arXiv:1412.6980, 2014. 
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#ref6" aria-label="Anchor">#</a></span>        
    
</h5>
        </br></br>
        
      </div>
      <script>

        var liked_article = false

        if (typeof auth !== 'undefined') {
          var oid = "views_posts\/report\/index.md"
          var id = oid ? oid.replaceAll("/", "-") : oid

          var viewed = localStorage.getItem(id);

          if (!viewed) {
            auth.signInAnonymously()
              .then(() => {
                var docRef = db.collection('views').doc(id)
                localStorage.setItem(id, true);
                docRef.get().then((doc) => {
                  if (doc.exists) {
                    db.collection('views').doc(id).update({
                      views: firebase.firestore.FieldValue.increment(1)
                    });
                  } else {
                    db.collection('views').doc(id).set({ views: 1 })
                  }
                }).catch((error) => {
                  console.log("Error getting document:", error);
                });
              })
              .catch((error) => {
                var errorCode = error.code;
                var errorMessage = error.message;
                console.error(errorCode, errorMessage)
              });
          }

          var oid_likes = "likes_posts\/report\/index.md"
          var id_likes = oid_likes ? oid_likes.replaceAll("/", "-") : oid_likes

          var liked = localStorage.getItem(id_likes);

          if (liked) {
            liked_article = true
            document.querySelectorAll("span[id='likes_button_heart']")[0].style.display = ""
            document.querySelectorAll("span[id='likes_button_emtpty_heart']")[0].style.display = "none"
            document.querySelectorAll("span[id='likes_button_text']")[0].innerText = ""
          }

        }

        function like_article(id_likes) {
          auth.signInAnonymously()
            .then(() => {
              var docRef = db.collection('likes').doc(id_likes)
              docRef.get().then((doc) => {
                liked_article = true
                localStorage.setItem(id_likes, true);
                document.querySelectorAll("span[id='likes_button_heart']")[0].style.display = ""
                document.querySelectorAll("span[id='likes_button_emtpty_heart']")[0].style.display = "none"
                document.querySelectorAll("span[id='likes_button_text']")[0].innerText = ""
                if (doc.exists) {
                  db.collection('likes').doc(id_likes).update({
                    likes: firebase.firestore.FieldValue.increment(1)
                  });
                } else {
                  db.collection('likes').doc(id_likes).set({ likes: 1 })
                }
              }).catch((error) => {
                console.log("Error getting document:", error);
              });
            })
            .catch((error) => {
              var errorCode = error.code;
              var errorMessage = error.message;
              console.error(errorCode, errorMessage)
            });
        }

        function remove_like_article(id_likes) {
          auth.signInAnonymously()
            .then(() => {
              var docRef = db.collection('likes').doc(id_likes)
              docRef.get().then((doc) => {
                liked_article = false
                localStorage.removeItem(id_likes);
                document.querySelectorAll("span[id='likes_button_heart']")[0].style.display = "none"
                document.querySelectorAll("span[id='likes_button_emtpty_heart']")[0].style.display = ""
                document.querySelectorAll("span[id='likes_button_text']")[0].innerText = "\xa0Like"
                if (doc.exists) {
                  db.collection('likes').doc(id_likes).update({
                    likes: firebase.firestore.FieldValue.increment(-1)
                  });
                } else {
                  db.collection('likes').doc(id_likes).set({ likes: 0 })
                }
              }).catch((error) => {
                console.log("Error getting document:", error);
              });
            })
            .catch((error) => {
              var errorCode = error.code;
              var errorMessage = error.message;
              console.error(errorCode, errorMessage)
            });
        }

        function process_article() {
          var oid_likes = "likes_posts\/report\/index.md"
          var id_likes = oid_likes ? oid_likes.replaceAll("/", "-") : oid_likes
          if (!liked_article) {
            like_article(id_likes)
          } else {
            remove_like_article(id_likes)
          }
        }

      </script>
  </section>
  <footer class="pt-8 max-w-prose print:hidden">

    


    
    
    

    

    

    

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/Deep-Color-Transfer/posts/progress/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Progress Report</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2022-10-23 00:00:00 &#43;0000 UTC">23 October 2022</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


    
  </footer>
</article>

      
      <div class="pointer-events-none absolute top-[100vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
        <a href="#the-top"
          class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
          aria-label="" title="">
          &uarr;
        </a>
      </div>
      
    </main><footer class="py-10 print:hidden">
  
  
    
    <nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex flex-col list-none sm:flex-row">
        
        <li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
          <a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" href=""
            title=""></a>
        </li>
        
      </ul>
    </nav>
    
  
  <div class="flex items-center justify-between">

    
    

    
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/Deep-Color-Transfer/js/process.min.2166d3adac1679c00a75161830ab5725d3efc0e3d3f8c2453fb01d0907948436c25f0f8a7ad824322fa22f3f9c85fd4d0a1d5c856f53b862157da25a57dc3d52.js" integrity="sha512-IWbTrawWecAKdRYYMKtXJdPvwOPT&#43;MJFP7AdCQeUhDbCXw&#43;KetgkMi&#43;iLz&#43;chf1NCh1chW9TuGIVfaJaV9w9Ug=="></script>
  
  
</footer><div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="https://wp-zhang.github.io/Deep-Color-Transfer/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

</html>
